#+title: Lab 5

#+begin_src jupyter-julia
include("main.jl") 
#+end_src

#+RESULTS:
: # Out[119]:
: : predict (generic function with 3 methods)

* Loading dataset
#+begin_src jupyter-julia
chips = read_dataframe("./data/chips.csv")
geyser = read_dataframe("./data/geyser.csv")
#+end_src

#+RESULTS:
#+begin_example
# Out[2]:
,#+BEGIN_EXAMPLE
  222-element Vector{Object}:
  Object([1.0, 4.4], :N)
  Object([1.0, 3.9], :N)
  Object([1.0, 4.0], :P)
  Object([1.0, 4.0], :N)
  Object([1.0, 3.5], :N)
  Object([1.0, 4.1], :N)
  Object([1.0, 2.3], :P)
  Object([1.0, 4.7], :N)
  Object([1.0, 1.7], :P)
  Object([1.0, 4.9], :N)
  Object([1.0, 1.7], :P)
  Object([1.0, 4.6], :N)
  Object([1.0, 3.4], :N)
  ⋮
  Object([23.0, 2.2], :P)
  Object([23.0, 4.7], :N)
  Object([23.0, 4.0], :P)
  Object([23.0, 1.8], :P)
  Object([23.0, 4.7], :N)
  Object([23.0, 1.8], :P)
  Object([23.0, 4.5], :N)
  Object([23.0, 2.1], :P)
  Object([23.0, 4.2], :N)
  Object([23.0, 2.1], :P)
  Object([23.0, 5.2], :N)
  Object([23.0, 2.0], :P)
,#+END_EXAMPLE
#+end_example

* Plots
#+begin_src jupyter-julia
using Plots 
#+end_src

#+RESULTS:
: # Out[3]:


#+begin_src jupyter-julia
function data_for_scatter(objects::Vector{Object})::Tuple{Tuple{Vector{Float64}, Vector{Float64}}, Tuple{Vector{Float64}, Vector{Float64}}}
    N = filter(o -> o.y == :N, objects)
    P = filter(o -> o.y == :P, objects)
    ext(i, a) = map(o -> o.x[i], a)
    return ((ext(1, P), ext(2, P)), (ext(1, N), ext(2, N)))
end
#+end_src

#+RESULTS:
: # Out[4]:
: : data_for_scatter (generic function with 1 method)

#+begin_src jupyter-julia
function overlay_scatter(p, objects::Vector{Object})
    (Px1, Px2), (Nx1, Nx2) = data_for_scatter(objects)
    prev_plot = isnothing(p) ? () : (p,)
    scatter1 = scatter(prev_plot..., Nx1, Nx2, c = :blue, label = "N")
    scatter(scatter1, Px1, Px2, c = :red, label = "P")
end
#+end_src

#+RESULTS:
: # Out[5]:
: : overlay_scatter (generic function with 1 method)

#+begin_src jupyter-julia :results raw drawer
overlay_scatter(nothing, chips) 
#+end_src

#+RESULTS:
:results:
# Out[6]:
[[file:./obipy-resources/jvKeFb.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
overlay_scatter(nothing, geyser) 
#+end_src

#+RESULTS:
:results:
# Out[7]:
[[file:./obipy-resources/7VxINs.svg]]
:end:

#+begin_src jupyter-julia
function plot_space(clf, data; do_fit=true)
    if do_fit
        fit(clf, data)
    end
    f(x1, x2) = predictw(clf, [x1, x2])

    rx = range(minimum(o -> o.x[1], data),stop=maximum(o -> o.x[1], data),length=100)
    ry = range(minimum(o -> o.x[2], data),stop=maximum(o -> o.x[2], data),length=100)

    p = heatmap(rx, ry, f, c = :bluesreds, clims=(-1, 1))
    overlay_scatter(p, data)
end
#+end_src

#+RESULTS:
: # Out[36]:
: : plot_space (generic function with 1 method)

** Random Forest
#+begin_src jupyter-julia :results raw drawer
mk_rf(ntrees) = mk_random_forest(;dt_params=(:split_score_fun_name => :entropy,), ntrees=ntrees, positive_class=:P)
p10 = plot_space(mk_rf(10), chips)
p100 = plot_space(mk_rf(100), chips)
p1000 = plot_space(mk_rf(1000), chips)
p10000 = plot_space(mk_rf(10000), chips)
plot(p10, p100, p1000, p10000, titles = ["10 Trees" "100 Trees" "1000 Trees" "10000 Trees"], size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[31]:
[[file:./obipy-resources/CD2XiA.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
rf = mk_random_forest(;dt_params=(:split_score_fun_name => :entropy,), ntrees=200, positive_class=:P)
scores = []
function rf_score(clf::RandomForest, i::Int64)
    push!(scores, estimate(clf, chips))
end
fit(rf, chips; cb=rf_score)
plot(1:size(scores)[1], scores, label="f-score")
#+end_src

#+RESULTS:
:results:
# Out[121]:
[[file:./obipy-resources/TNAkO5.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
mk_rf(ntrees) = mk_random_forest(;dt_params=(:split_score_fun_name => :entropy,), ntrees=ntrees, positive_class=:P)
p10 = plot_space(mk_rf(10), geyser)
p100 = plot_space(mk_rf(100), geyser)
p1000 = plot_space(mk_rf(1000), geyser)
p10000 = plot_space(mk_rf(10000), geyser)
plot(p10, p100, p1000, p10000, titles = ["10 Trees" "100 Trees" "1000 Trees" "10000 Trees"], size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[83]:
[[file:./obipy-resources/LTQvk5.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
rf = mk_random_forest(;dt_params=(:split_score_fun_name => :entropy,), ntrees=200, positive_class=:P)
scores = []
function rf_score(clf::RandomForest, i::Int64)
    push!(scores, estimate(clf, geyser))
end
fit(rf, geyser; cb=rf_score)
plot(1:size(scores)[1], scores, label="f-score")
#+end_src

#+RESULTS:
:results:
# Out[122]:
[[file:./obipy-resources/JlOFaI.svg]]
:end:

** AdaBoost
#+begin_src jupyter-julia :results raw drawer
N = 9
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:entropy) for _ in 1:100]; positive_class=:P)
ids = gen_fibs(N)
plots = []
titles = []
function adaboost_plot(clf::AdaBoost, i::Int64)
    if i ∈ ids
        push!(plots, plot_space(clf, chips; do_fit=false))
        push!(titles, "$(i) Iteration")
    end
end
fit(ab, chips; cb=adaboost_plot)
plot(plots..., titles=reshape(titles, (1, N)), size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[54]:
[[file:./obipy-resources/MeIr5P.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
N = 9
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:entropy) for _ in 1:100]; positive_class=:P)
ids = gen_fibs(N)
plots = []
titles = []
function adaboost_plot(clf::AdaBoost, i::Int64)
    if i ∈ ids
        push!(plots, plot_space(clf, geyser; do_fit=false))
        push!(titles, "$(i) Iteration")
    end
end
fit(ab, geyser; cb=adaboost_plot)
plot(plots..., titles=reshape(titles, (1, N)), size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[79]:
[[file:./obipy-resources/YnOzl5.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:entropy) for _ in 1:6]; positive_class=:P)
scores = []
function adaboost_score(clf::AdaBoost, i::Int64)
    push!(scores, estimate(clf, chips; predict_kwargs=(:negative_class => :N,)))
end
fit(ab, chips; cb=adaboost_score)
plot(1:size(scores)[1], scores, label="f-score")
#+end_src

#+RESULTS:
:results:
# Out[77]:
[[file:./obipy-resources/sN72CP.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:entropy) for _ in 1:10]; positive_class=:P)
scores = []
function adaboost_score(clf::AdaBoost, i::Int64)
    push!(scores, estimate(clf, geyser; predict_kwargs=(:negative_class => :N,)))
end
fit(ab, geyser; cb=adaboost_score)
plot(1:size(scores)[1], scores, label="f-score", ylims=(0, 1.))
#+end_src

#+RESULTS:
:results:
# Out[82]:
[[file:./obipy-resources/HSDJjm.svg]]
:end:

** Random Forest Gini
#+begin_src jupyter-julia :results raw drawer
mk_rf(ntrees) = mk_random_forest(;dt_params=(:split_score_fun_name => :gini,), ntrees=ntrees, positive_class=:P)
p10 = plot_space(mk_rf(10), chips)
p100 = plot_space(mk_rf(100), chips)
p1000 = plot_space(mk_rf(1000), chips)
p10000 = plot_space(mk_rf(10000), chips)
plot(p10, p100, p1000, p10000, titles = ["10 Trees" "100 Trees" "1000 Trees" "10000 Trees"], size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[112]:
[[file:./obipy-resources/bBjs1a.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
rf = mk_random_forest(;dt_params=(:split_score_fun_name => :gini,), ntrees=200, positive_class=:P)
scores = []
function rf_score(clf::RandomForest, i::Int64)
    push!(scores, estimate(clf, chips))
end
fit(rf, chips; cb=rf_score)
plot(1:size(scores)[1], scores, label="f-score")
#+end_src

#+RESULTS:
:results:
# Out[123]:
[[file:./obipy-resources/LddKnl.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
mk_rf(ntrees) = mk_random_forest(;dt_params=(:split_score_fun_name => :gini,), ntrees=ntrees, positive_class=:P)
p10 = plot_space(mk_rf(10), geyser)
p100 = plot_space(mk_rf(100), geyser)
p1000 = plot_space(mk_rf(1000), geyser)
p10000 = plot_space(mk_rf(10000), geyser)
plot(p10, p100, p1000, p10000, titles = ["10 Trees" "100 Trees" "1000 Trees" "10000 Trees"], size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[113]:
[[file:./obipy-resources/HecEu1.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
rf = mk_random_forest(;dt_params=(:split_score_fun_name => :gini,), ntrees=200, positive_class=:P)
scores = []
function rf_score(clf::RandomForest, i::Int64)
    push!(scores, estimate(clf, geyser))
end
fit(rf, geyser; cb=rf_score)
plot(1:size(scores)[1], scores, label="f-score")
#+end_src

#+RESULTS:
:results:
# Out[126]:
[[file:./obipy-resources/qbus4d.svg]]
:end:

** AdaBoost Gini
#+begin_src jupyter-julia :results raw drawer
N = 9
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:gini) for _ in 1:100]; positive_class=:P)
ids = gen_fibs(N)
plots = []
titles = []
function adaboost_plot(clf::AdaBoost, i::Int64)
    if i ∈ ids
        push!(plots, plot_space(clf, chips; do_fit=false))
        push!(titles, "$(i) Iteration")
    end
end
fit(ab, chips; cb=adaboost_plot)
plot(plots..., titles=reshape(titles, (1, N)), size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[105]:
[[file:./obipy-resources/GRPztp.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
N = 9
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:gini) for _ in 1:100]; positive_class=:P)
ids = gen_fibs(N)
plots = []
titles = []
function adaboost_plot(clf::AdaBoost, i::Int64)
    if i ∈ ids
        push!(plots, plot_space(clf, geyser; do_fit=false))
        push!(titles, "$(i) Iteration")
    end
end
fit(ab, geyser; cb=adaboost_plot)
plot(plots..., titles=reshape(titles, (1, N)), size=(1280, 720))
#+end_src

#+RESULTS:
:results:
# Out[106]:
[[file:./obipy-resources/5OXsQs.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:gini) for _ in 1:25]; positive_class=:P)
scores = []
function adaboost_score(clf::AdaBoost, i::Int64)
    push!(scores, estimate(clf, chips; predict_kwargs=(:negative_class => :N,)))
end
fit(ab, chips; cb=adaboost_score)
plot(1:size(scores)[1], scores, label="f-score")
#+end_src

#+RESULTS:
:results:
# Out[108]:
[[file:./obipy-resources/Q7Of8E.svg]]
:end:

#+begin_src jupyter-julia :results raw drawer
ab = mk_ada_boost([mk_decision_tree(max_depth=3, split_score_fun_name=:gini) for _ in 1:10]; positive_class=:P)
scores = []
function adaboost_score(clf::AdaBoost, i::Int64)
    push!(scores, estimate(clf, geyser; predict_kwargs=(:negative_class => :N,)))
end
fit(ab, geyser; cb=adaboost_score)
plot(1:size(scores)[1], scores, label="f-score", ylims=(0, 1.))
#+end_src

#+RESULTS:
:results:
# Out[111]:
[[file:./obipy-resources/pGq4zm.svg]]
:end:
