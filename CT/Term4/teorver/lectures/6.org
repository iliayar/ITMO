#+LATEX_CLASS: general
#+TITLE: Лекция 6
#+AUTHOR: Ilya Yaroshevskiy

#+begin_export latex
\newcommand{\todo}{{\color{red}\text{Доделать }}}
\newcommand{\fixme}{{\color{red}\text{Исправить }}}

#+end_export


* Случайные величины
#+begin_symb org
\(\xi\) --- *Случайная величина*
#+end_symb
#+begin_examp org
\(\xi\) --- число выпавших очков. \(\xi \in \{1, 2, 3, 4, 5, 6\}\)
#+end_examp
#+begin_examp org
\(\xi\) --- время работы микросхемы до отказа
1. Время работы в часах \\
   \(\xi = \{1, 2, 3, \dots \}\)
2. Время работы измеряем точно \\
   \(\xi \in [0, +\infty]\)
#+end_examp
#+begin_examp org
\(\xi\) --- температура воздуха в случайный момент времени. \(\xi \in (-50^\circ, 50^\circ)\)
#+end_examp
#+begin_examp org
Индикатор события \(A\).
\[I_A(\omega) \in \begin{cases} 0 & , \omega \not \in A \\ 1 & , \omega \in A\end{cases}\]
#+end_examp
#+begin_definition org
Пусть имеется вероятностное пространство \((\Omega, \mathcal{F}, p)\). Функция \(\xi: \Omega \to \R\) называется *\(\mathcal{F}\)-измеримой*, если \(\forall x \in \R:\ \{\omega | \xi(\omega) < x\} \in \mathcal{F}\). Т.е прообраз \(\xi^{-1}((- \infty, x)) \in \mathcal{F}\)
#+end_definition
#+begin_definition org
*Случайной величиной* \(\xi\) заданной на вероятностном пространстве \((\Omega, \mathcal{F}, p)\)  называется \(\mathcal{F}\)-измеримая функция \fixme, ставящая в соответствие каждому элементарному исходу \(\omega\) некоторое вещественное число
#+end_definition
#+begin_examp org
Бросаем кость.
- \(\Omega = \{1, 2, 3, 4, 5, 6\}\)
- \(\mathcal{F} = \{\emptyset, \Omega, \{1, 3, 5\}, \{2, 4, 6\}\}\)
- \(] \xi(i) = i\)
Если \(x = 4\), то \(\{\omega | \xi(\omega) < 4\} = \{1, 2, 3\} \not\in \mathcal{F}\) \Rightarrow \(\xi\) не является \(\mathcal{F}\)-измеримой
#+end_examp
** Смысл измеримости
Пусть случайная величина \(\xi: \Omega \to \R\) --- измеримая. Тогда \(P(\xi < x) = P(\{\omega | \xi(\omega) < x\})\), т.к. \(A_x = \{\omega | \xi(\omega) < x\} \in \mathcal{F}\). Тогда \[\overline{A_x} = \{\omega | \xi(\omega) \ge x\} \in \mathcal{F}\] \[A_x \setminus B_y = \{\omega | t \le \xi(\omega) le x\} \in \mathcal{F}\]
\[ B_x = \todo \]
\[ B_x \setminus A_x = \{\omega | \xi(\omega) = x\} \in \mathcal{F} \]
Отсюда видим, по теореме Каво?\fixme  можно однозначно продолжить до любого Борелевского множества на прямой. \(B \in \mathcal{B}\) --- Борелевская \(\sigma\)-алгебра. \(P(B \in \mathcal{B}) = P\{\omega | \xi(\omega) \in B\}\) \\
Пусть случайная величина задана на вероятностном пространстве \((\Omega, \mathcal{F}, p)\). Тогда:
1. \((\Omega, \mathcal{F}, p) \xrightarrow[]{\xi} (\R, \mathcal{B}, p)\) --- новое вероятностное пространство
2. \(\xi^{-1}(B)\ \forall B \in \mathcal{B}\) \\
   \(\mathcal{F}_\xi \subset \mathcal{F}\) \\
   \(\mathcal{F}_\xi\) --- \(\sigma\)-алгебра порожденная величиной \(\xi\)
#+begin_task org
Найти \(\sigma\)-алгебру порожденную индикатором
#+end_task
#+begin_definition org
Функция \(P(B)\ B \in \mathcal{B}\) называется *распределением вероятностей* случайной величины \(\xi(\omega)\). Т.е. распределение случайной величины это соответствие множествами на вещественной прямой и вероятностями случайной величины попасть в это множество
#+end_definition
** Типы распределения
- Дискретные
- Абсолютно непрерывные
- Смешанные
- Сингулярные (непрерывные но не абсолютно непрерывные)
*** Дискретные
Случайная величина \(\xi\) имеет дискретное распределение, если она принимает не более чем счетное число значений, т.е. существует конечный или счетный набор чисел \(\{x_1, x_2, \dots, x_n, \dots\}\), такой что
1. \(p_i = p(\xi = x_i) > 0\)
2. \(\sum\limits_i p_i = 1\)
| /       | <       |         |           |         |          |
| \(\xi\) | \(x_1\) | \(x_2\) | \(\dots\) | \(x_n\) | \(\dots\) |
|---------+---------+---------+-----------+---------+-----------|
| \(p\)   | \(p_1\) | \(p_2\) | \(\dots\) | \(p_n\) | \(\dots\) |
\todo
#+NAME: dice_examp
#+begin_examp org
Кость
| /       |  <              |                 |                 |                 |                 |                 |
| \(\xi\) |               1 |               2 |               3 |               4 |               5 |               6 |
|---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------|
| \(p\)   | \(\frac{1}{6}\) | \(\frac{1}{6}\) | \(\frac{1}{6}\) | \(\frac{1}{6}\) | \(\frac{1}{6}\) | \(\frac{1}{6}\) |
\todo
#+end_examp
**** Основные числовые характеристики
***** Математическое ожидание(среднее значение)
#+begin_defintion org
*Математическим ожиданием* случайной величины \(\xi\) называется число:
\[ E\xi = \sum\limits_i x_i p_i \] при условии что данный ряд сходится абсолютно, иначе говорят что математическое ожидание не существует
#+end_defintion
#+begin_symb org
E\xi
#+end_symb
#+begin_remark org
Смысл: среднее значение, число вокруг которого группируется значения случайной величины. Физический смысл: центр масс. Статистический смысл: среднее арифметическое наблюдаемых значений при большом значении реальных экспериментов
#+end_remark
***** Дисперсия
#+begin_definition org
*Дисперсией* \(D\xi\) случайной величины \(\xi\) называется среднее квадратов отклонений ее от математического ожидания
\[ D\xi = E(\xi - E\xi)^2 \] или \[D\xi = \sum\limits_i (x_i - E\xi)^2 p_i \]
При условии что данное среднее значение существует(конечно)
#+end_definition
#+begin_remark org
Вычислять дисперсию удобнее по формуле \[ D\xi = E\xi^2 - (E\xi)^2  = \sum\limits_i x_i^2p_i - (E\xi)^2\]
#+end_remark
#+begin_remark org
Смысл: квадрат среднего разброса(рассеяния) случайной величины около ее математического ожидания
#+end_remark
***** Среднее квадратичное отклонение
#+begin_definition org
*Средним квадратичным отклонением* (\sigma_\xi = \sigma(\xi)) случайной величины \(\xi\) называется число
\[ \sigma = \sqrt{D\xi} \]
#+end_definition
#+begin_remark org
Смысл: характеризует средний разброс случайной величины около ее математического ожидания
#+end_remark
#+begin_examp org
[[dice_examp][Бросаем кость]]
\[ E\xi = 1\cdot \frac{1}{6} + 2 \cdot \frac{1}{6}  + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5 \]
\[ D\xi = 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + 3^2 \cdot \frac{1}{6} + 4^2 \cdot \frac{1}{6} + 5^2 \cdot \frac{1}{6} + 6^2 \cdot \frac{1}{6} - 3.5^2 = 2.92 \]
\[ \sigma = \sqrt{2.92} \approx 1 \neq 1 \]
#+end_examp
**** Свойства математического ожидания и дисперсии
#+begin_definition org
Случайная величина \(\xi\) имеет вырожденное распределение, если \(\xi(\omega) = C = \const\ \forall \omega \in \Omega\) или \(p(\xi = C) = 1\)
\[ E \xi = C = \const \]
\[ D \xi = 0 \]
#+end_definition
#+begin_proof org
\todo
#+end_proof
#+ATTR_LATEX: :options [Свойство сдвига]
#+begin_definition org
\[E(\xi + C) + E\xi + C\]
\[ D(\xi + C) = D \xi \]
#+end_definition
#+begin_proof org
\todo
#+end_proof
#+begin_definition org
\[ E(C\xi) = CE\xi \]
\[ D(C\xi) = C^2D\xi \]
#+end_definition
#+begin_proof org
\todo
#+end_proof
#+begin_definition org
\[ E(\xi + \eta) = E\xi + E\eta \]
#+end_definition
#+begin_proof org
\-
- Пусть \(x_i, y_i\) --- соответствующие значения случайных величин \(xi\) и \(mu\)
\[ E(\xi + \eta) = \sum\limits_{i, j} (x_i + y_j) p(\xi = x_i, \eta = y_j) = \sum\limits_i x_i \sum\limits_j p(\xi = x_i, \eta = y_j) + \sum\limits_j y_j \sum p(\xi = x_i, \eta = y_j) \]
\todo
#+end_proof
#+NAME: indep
#+begin_definition org
Дискретные случайные величины *независимы* если \(\forall i, j\ p(\xi = x_i, \eta = y_j) = p(\xi = x_i) \cdot p(\eta = y_j)\)
#+end_definition
#+begin_remark org
Если \(xi\) и \(\eta\) независимы, то
\[ E(\xi\eta) = E\xi\cdot E\eta \]
обратное не верно
#+end_remark
#+begin_proof org
\[ E(\xi\eta) = \sum\limits_{ij} (x_i y_j)p(\xi = x_i, \eta = y_j) = \sum\limits_i x_i \sum\limits_j y_j(\xi = x_i, \eta = y_j) = \]
\[ = \sum\limits_i x_i \sum\limits_j y_j p(\xi = x_j)p(\eta = y_j) = \sum\limits_i x_i p(\xi = x_i) \cdot \sum\limits_j y_j p(\eta = y_j) = E\xi \cdot E\eta\]
#+end_proof
#+begin_proof org
\[ D\xi = E\xi^2 - (E\xi)^2 \]
\[ D\xi = E(\xi - E\xi)^2 = E(\xi - 2\xi E\xi + (E\xi)^2) = E\xi^2 - 2E\xi E\xi + E(E\xi)^2 = \]
\[ E\xi^2 - 2(E\xi)^2 + (E\xi)^2 = E\xi^2 - (E\xi)^2 \]
#+end_proof
#+begin_remark org
\[ D(\xi + \eta) = D\xi + D\eta + 2\text{Cov}(\xi, eta) \]
, где \(\text{Cov}(\xi, \eta) = E(\xi\eta) - E\xi\cdot E\eta\) --- *ковариация*
#+end_remark
#+begin_proof org
\[ D(\xi + \eta) = E(\xi + \eta)^2 - (E(\xi + \eta))^2 = E\xi^2 + 2E\xi\eta + E\eta^2 - (E\xi)^2 - 2E\xi\cdot E\eta - (E\eta)^2 = \]
\[ D\xi + D\eta + 2(E(\xi\eta) - E\xi \cdot E\eta) \]
#+end_proof
#+begin_remark org
Если случайные величины \(\xi\) и \(\eta\) независимые, то
\[ D(\xi + \eta) = D\xi + \eta \]
#+end_remark
#+begin_proof org
По [[indep][свойству]] \(\text{Cov}(\xi, \eta) = 0\)
#+end_proof
#+begin_remark org
Среднее квадратичное отклонение --- минимум отклонения случайной величины от точек вещественной прямой, т.е.
\[ D\xi = \min\limits_a (y - a) \fixme \]
#+end_remark
#+begin_proof org
\[ E(\xi - a)^2 = E((\xi - E\xi) + (E\xi - a))^2 = E(\xi - E\xi)^2 + \underbrace{2E(\xi - E\xi)\cdot(E\xi - a)}_0 + (E\xi - a)^2 =  \]
\[ = D\xi + (E\xi - a)^2 \le D\xi \]
#+end_proof
**** Другие числовые характеристики
#+begin_remark org
\[ m_k = E\xi^k \] --- момент \(k\)-того порядка \\
В частности \(m_1 = E\xi\)
#+end_remark
#+begin_remark org
\[ E|\xi|^k \] --- абсолютный момент \(k\)-того порядка
#+end_remark
#+begin_remark org
\[ \mu_k = E(\xi - E\xi)^k \] --- центральный момент \(k\)-того порядка \\
В частности \(\mu_2 = D\xi\)
#+end_remark
#+begin_remark org
\[ E|\xi - E\xi|^2 \] --- абсолютный центральный момент \(k\)-того порядка
#+end_remark
#+begin_remark org
Центральные моменты можно выразить через относительные моменты
\todo
#+end_remark
#+begin_remark org
*Модой* \(\text{Mo}\) называется такое значение случайной величины, где вероятность события является наибольшей
\[ p(\xi = \text{Mo}) = \max\limits_i p_i \]
#+end_remark
#+begin_definition org
*Медианой* \(\text{Me}\) называется значение случайной величины такое что, \[p(\xi < \text{Me}) = p(\xi > \text{Me}) = \frac{1}{2}\]
#+end_definition

