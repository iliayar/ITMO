#+LATEX_CLASS: general
#+TITLE: Лекция 7
#+AUTHOR: Ilya Yaroshevskiy

#+begin_export latex
\newcommand{\diff}[2]{\frac{\partial #1}{\partial #2}}
#+end_export


* Критерии Сильвестра
** Достаточный условия
1. \(H(x^*) > 0\) и \(x^*\) --- локальный минимум \Leftrightarrow \(\Delta_1 > 0, \Delta_2 > 0, \dots , \Delta_n > 0\)
2. \(H(x^*) < 0\) и \(x^*\) --- локальный максимум \Leftrightarrow \(\Delta_1 < 0, \Delta_2 > 0, \dots , (-1)^n\Delta_n > 0\)
, где \(\Delta_i\) --- угловой минор
** Необходимые условия
1. \(H(x^*) \ge 0 \) и \(x^*\) --- может быть локальный минимум \Leftrightarrow \(\Delta_1 \ge 0, \Delta_2 \ge 0, \dots, \Delta_n \ge 0\)
2. \(H(x^*) \le 0\) и \(x^*\) --- может быть локальный максимум \Leftrightarrow \(\Delta_1 \le 0, \Delta_2 \ge 0, \dots, (-1)^n\Delta_n \ge 0\)
, где \(\Delta_i\) --- главный минор

* Собственные значения
#+begin_definition org
*Собственные значения* \(\lambda_i\ (i = 1..n)\) \(H(x^*)_{n\times n}\) находятся как корни характеристического уравнения \(|H(x^*) - \lambda E| = 0\). Если \(H(x)\) --- вещественная, симметричная матрица, то \(\lambda_i\) --- вещественные
#+end_definition
* Общие прицнипы многмерной оптимизации
** Выпуклые квадратичные функции
\[ f(x) = \frac{1}{2}ax^2 + bx + c \]
#+begin_definition org
Функция вида
\[ f(x) = \sum^n_{i = 1}\sum^n_{j = 1}a_{ij}x_ix_j + \sum^n_{j = 1}b_j x_j + c \addtag\label{7_1_quad} \]
Называется *квадратичной функией \(n\) перменных*
#+end_definition
Положим \(a_{ij} = a_{ij} + a_{ji}\)\({\color{red}??}\) \Rightarrow симметрия. матрица \(A\)
\[ f(x) = \frac{1}{2}(Ax, x) + (b, x) + c \]
, где \(b = (b_1, \dots b_n)^T \in E_n\) --- вектор коэффицентов, \(x = (x_1, \dots, x_n)^T\). \(x, y\) --- скалярное произведение
Свойства квадратичных функций:
1. \(\nabla f(x) = Ax + b\)
   \[ \diff{f}{x_k} = \diff{}{x_k}\left(\frac{1}{2}\sum^n_{i = 1}\sum^n_{j = 1}a_{ij}x_ix_j + \sum^n_{j = 1}b_j x_j + c\right) = \]
   \[ \frac{1}{2}\sum^n_{i = 1}(a_{ik} + a_{ki})x_i + b_k = \sum^n_{i = 1} a_{ki}x_i + b_k \]
2. \(H(x) = A\), где \(H(x)\) --- Гессиан\(\color{red}???\) 
   \[ \diff{^2 f}{x_l \partial x_k} = \diff{}{x_k}\left(\diff{f}{x_k}\right) = \diff{}{x_l}\left(\sum^n_{i = 1} a_{ki} x_i + b_k\right) \]
3. Квадратичная функция \(f(x)\) с положительно определенной матрицей \(A\) сильно выпукла
   \[ A = \begin{vmatrix} \lambda_1 & 0 & \dots & 0 \\ 0 & \lambda_2 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & \lambda_n \end{vmatrix} \]
   \[ A - lE = \begin{vmatrix} \lambda_1 - l & 0 & \dots & 0 \\ 0 & \lambda_2 - l & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & \lambda_n - l \end{vmatrix} \]
   В этом базисе все угловые миноры матрцы \(A\) и матрицы \(A - lE\) --- положительны при достаточно малом \(l: 0 < l < \lambda_\min \Rightarrow f(x)\) --- сильно выпукла
** Принципы многмерной оптимизации
\[ f(x) \to \min,\ x \in E_n \]
\[ x^{k + 1} = \Phi(x^k, x^{k + 1}, \dots x)^0,\ x^0 \in E_n \addtag\label{5_3_iter} \]
--- итериционная процедура(общего вида)
- \(\{x^k\}\): ::
  \[ \lim_{k \to \infty} f(x^k) = f^* = \min_{E_n} f(x), \text{ если } U^* \neq \emptyset \]
  \[ \lim_{k \to \infty} f(x^k) = f^* = \inf_{E_n} f(x), \text{ если } U^* = \emptyset \]
, где \(U^*\) -- множестве точек глобального минимума функции \(f(x)\) \\
\(\{x^k\} + \) условие \ref{5_3_iter} = минимизирующая последовательность для \(f(x)\) \\
Если для \(U^* \neq \emptyset\) выполняется условие
\[ \lim_{k \to \infty} \rho(x^k, U^*) = 0 \], то \(x^k\) сходится к множеству \(U^*\). Если \(U^*\) содежит единственную точку \(x^*\), то для \(\{x^k\}\) сходящейся к \(U^*\) будет справедливо \(\lim_{k \to \infty} x^k = x^*\)
#+begin_definition org
\(\rho(x, U) = \inf_{y \in U}\rho(x, y)\) --- растояние от точки \(x\) до множества \(U\)
#+end_definition
#+begin_remark org
Минимизирующая последовательность \(\{x^k\}\) может и не сходится к точке минимума
#+end_remark
#+ATTR_LATEX: :options [Вейерштрасса]
#+begin_theorem org
Если \(f(x)\) непрерывна в \(E_n\) и множество \(U^\alpha = {x: f(x) \le \alpha}\) для некоторого \(\alpha\) непусто и ограничено, то \(f(x)\) достигает глобального минимума в \(E_n\)
#+end_theorem
*** Скорость сходимости(минизирующих последовательностей)
#+begin_definition org
\(\{x^k\}\) сходится к точке \(x^*\) *линейно* (со скоростью геометрической последовательности), если \(\exists q \in (0, 1):\)
\[ \rho(x^k, x^*) \le q \rho(x^{k - 1}, x^*) \addtag\label{5_5_linear}\]
\[ \rho(x^k, x^*) \le q^k \rho(x^0, x^*) \]
#+end_definition
#+begin_definition org
Сходимость называется *сверхлинейной* если
\[ \rho(x^k, x^*) \le q_k \rho(x^{k - 1}, x^*) \], и \(q_k \xrightarrow[k \to \infty]{} +0\)
#+end_definition
#+begin_definition org
*Квадратичная сходимость*:
\[ \rho(x^k, x^*) \le \left[ c \rho(x^{k - 1}, x^*)\right]^2,\ c > 0 \]
#+end_definition
*** Критерии окончания итерационного процесса
\[ \rho(x^{k + 1}, x^*) < \varepsilon_1 \]
\[ |f(x^{k + 1}) - f(x^k)| < \varepsilon_2 \addtag\label{5_6_eps2}\]
\[ \Vert \nabla f(x^k) \Vert < \varepsilon_3 \]
, где \(\varepsilon_i\) --- заранее заданные точности
\[ x^{k + 1} = x^k + \alpha_k p^k,\ k=0, 1, \dots \addtag\label{5_7_iter}\]
, где \(p^k\) --- направление поиска из \(x^k\) в \(x^{k + 1}\), \(\alpha_k\) --- величина шага
\[ f(x^{k + 1}) < f(x^k) \] --- условие выбора \(\alpha_k\)
#+begin_definition org
В итерационном процессе \ref{5_7_iter} производится *исчерпывающий спуск*, если величина шага \(\alpha_k\) находится из решения одномерной задачи минизации:
\[ \Phi_k(\alpha) \to \min_\alpha,\ \Phi_k(\alpha) = f(x^k + \alpha p^k) \addtag\label{5_8_cond}\]
#+end_definition
#+begin_theorem org
Если функция \(f(x)\) дифференцируема в пространстве \(E_n\), то в итерационном процессе \ref{5_7_iter} c выбором шага с ичерпывающим спуском для любого \(k \ge 1\):
\[ (\nabla f(x^{k + 1}), p^k) = 0 \addtag\label{5_9_orto}\]
--- это значит что эти два вектора ортогональны
#+end_theorem
\noindentдля \( \Phi_k(\alpha) \) необходимое условие минимума функции:
\[ \frac{d\Phi_k(\alpha)}{d \alpha} = \sum^n_{j = 1} \diff{f(x^{k + 1})}{x_j} \cdot \frac{d x_j^{k + 1}}{d \alpha} = 0 \]
учитывая \(x_j^{k + 1} = x_j^k + \alpha p_j^k \Rightarrow \frac{dx^k_j}{d\alpha} = p_j^k\)

#+begin_theorem org
Для квадратичной функции \(f(x) = \frac{1}{2}(Ax, x) + (b ,x) + c\) величина \(\alpha_k\) исчерпывающего спуска в итерационном процессе
\[ x^{k + 1} = x^k + \alpha_k p^k, \k = 0, 1, \dots \]
равна
\[ \alpha_k = -\frac{(\nabla f(x^k), p^k)}{(A p^k, p^k)} = - \frac{(Ax^k + b, p^k)}{(Ap^k, p^k)} \addtag\label{5_10_alpha}\]
#+end_theorem
