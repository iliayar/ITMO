% Created 2021-04-15 Thu 13:50
% Intended LaTeX compiler: pdflatex

  \documentclass[english]{article}
  \usepackage[T1, T2A]{fontenc}
\usepackage[lutf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage{minted}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{grffile}
\usepackage{extarrows}
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
\usepackage{rotating}
\usepackage{placeins}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{capt-of}
  
  \usepackage{geometry}
  \geometry{a4paper,left=2.5cm,top=2cm,right=2.5cm,bottom=2cm,marginparsep=7pt, marginparwidth=.6in}
   \usepackage{hyperref}
 \hypersetup{
     colorlinks=true,
     linkcolor=blue,
     filecolor=orange,
     citecolor=black,      
     urlcolor=cyan,
     }

\usetikzlibrary{decorations.markings}
\usetikzlibrary{cd}
\usetikzlibrary{patterns}
\usetikzlibrary{automata, arrows}

\newcommand\addtag{\refstepcounter{equation}\tag{\theequation}}
\newcommand{\eqrefoffset}[1]{\addtocounter{equation}{-#1}(\arabic{equation}\addtocounter{equation}{#1})}
\newcommand{\llb}{\llbracket}
\newcommand{\rrb}{\rrbracket}


\newcommand{\R}{\mathbb{R}}
\renewcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\A}{\mathfrak{A}}
\newcommand{\B}{\mathfrak{B}}
\newcommand{\rank}{\mathop{\rm rank}\nolimits}
\newcommand{\const}{\var{const}}
\newcommand{\grad}{\mathop{\rm grad}\nolimits}

\newcommand{\todo}{{\color{red}\fbox{\text{Доделать}}}}
\newcommand{\fixme}{{\color{red}\fbox{\text{Исправить}}}}

\newcounter{propertycnt}
\setcounter{propertycnt}{1}
\newcommand{\beginproperty}{\setcounter{propertycnt}{1}}

\theoremstyle{plain}
\newtheorem{propertyinner}{Свойство}
\newenvironment{property}{
  \renewcommand\thepropertyinner{\arabic{propertycnt}}
  \propertyinner
}{\endpropertyinner\stepcounter{propertycnt}}
\newtheorem{axiom}{Аксиома}
\newtheorem{lemma}{Лемма}
\newtheorem{manuallemmainner}{Лемма}
\newenvironment{manuallemma}[1]{%
  \renewcommand\themanuallemmainner{#1}%
  \manuallemmainner
}{\endmanuallemmainner}

\theoremstyle{remark}
\newtheorem*{remark}{Примечание}
\newtheorem*{solution}{Решение}
\newtheorem{corollary}{Следствие}[theorem]
\newtheorem*{examp}{Пример}
\newtheorem*{observation}{Наблюдение}

\theoremstyle{definition}
\newtheorem{task}{Задача}
\newtheorem{theorem}{Теорема}[section]
\newtheorem*{definition}{Определение}
\newtheorem*{symb}{Обозначение}
\newtheorem{manualtheoreminner}{Теорема}
\newenvironment{manualtheorem}[1]{%
  \renewcommand\themanualtheoreminner{#1}%
  \manualtheoreminner
}{\endmanualtheoreminner}
\captionsetup{justification=centering,margin=2cm}
\newenvironment{colored}[1]{\color{#1}}{}

\tikzset{->-/.style={decoration={
  markings,
  mark=at position .5 with {\arrow{>}}},postaction={decorate}}}
\makeatletter
\newcommand*{\relrelbarsep}{.386ex}
\newcommand*{\relrelbar}{%
  \mathrel{%
    \mathpalette\@relrelbar\relrelbarsep
  }%
}
\newcommand*{\@relrelbar}[2]{%
  \raise#2\hbox to 0pt{$\m@th#1\relbar$\hss}%
  \lower#2\hbox{$\m@th#1\relbar$}%
}
\providecommand*{\rightrightarrowsfill@}{%
  \arrowfill@\relrelbar\relrelbar\rightrightarrows
}
\providecommand*{\leftleftarrowsfill@}{%
  \arrowfill@\leftleftarrows\relrelbar\relrelbar
}
\providecommand*{\xrightrightarrows}[2][]{%
  \ext@arrow 0359\rightrightarrowsfill@{#1}{#2}%
}
\providecommand*{\xleftleftarrows}[2][]{%
  \ext@arrow 3095\leftleftarrowsfill@{#1}{#2}%
}
\makeatother

\newenvironment{rualgo}[1][]
  {\begin{algorithm}[#1]
     \selectlanguage{russian}%
     \floatname{algorithm}{Алгоритм}%
     \renewcommand{\algorithmicif}{{\color{red}\textbf{если}}}%
     \renewcommand{\algorithmicthen}{{\color{red}\textbf{тогда}}}%
     \renewcommand{\algorithmicelse}{{\color{red}\textbf{иначе}}}%
     \renewcommand{\algorithmicend}{{\color{red}\textbf{конец}}}%
     \renewcommand{\algorithmicfor}{{\color{red}\textbf{для}}}%
     \renewcommand{\algorithmicto}{{\color{red}\textbf{до}}}%
     \renewcommand{\algorithmicdo}{{\color{red}\textbf{делать}}}%
     \renewcommand{\algorithmicwhile}{{\color{red}\textbf{пока}}}%
     \renewcommand{\algorithmicrepeat}{{\color{red}\textbf{повторять}}}%
     \renewcommand{\algorithmicuntil}{{\color{red}\textbf{до тех пор пока}}}%
     \renewcommand{\algorithmicloop}{{\color{red}\textbf{повторять}}}%
     \renewcommand{\algorithmicnot}{{\color{blue}\textbf{не}}}%
     \renewcommand{\algorithmicand}{{\color{blue}\textbf{и}}}%
     \renewcommand{\algorithmicor}{{\color{blue}\textbf{или}}}%
     \renewcommand{\algorithmicrequire}{{\color{blue}\textbf{Ввод}}}%
     \renewcommand{\algorithmicrensure}{{\color{blue}\textbf{Вывод}}}%
     \renewcommand{\algorithmicreturn}{{\color{red}\textbf{Вернуть}}}%
     \renewcommand{\algorithmicrtrue}{{\color{blue}\textbf{истинна}}}%
     \renewcommand{\algorithmicrfalse}{{\color{blue}\textbf{ложь}}}%
     % Set other language requirements
  }
  {\end{algorithm}}
\author{Ilya Yaroshevskiy}
\date{\today}
\title{Лекция 8}
\hypersetup{
 pdfauthor={Ilya Yaroshevskiy},
 pdftitle={Лекция 8},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.0.50 (Org mode 9.4.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\begin{definition}
Направление вектора \(p^k\) называется \textbf{направлением убывания} функции \(f(x)\) в точке \(x^*\), если при всех достаточно малых положительных \(\alpha\) выполняется неравенство: \[f(x^k + \alpha p^k)  < f(x^k)\]
\end{definition}
\begin{theorem}[достаточное условие направления убывания]
Пусть функция \(f(x)\) дифференцируема в точке \(x^k\). Если вектор \(p^k\) удовлетворяет условию:
\[ (\nabla f(x^k), p^k) < 0 \]
, то направление вектора \(p^k\) является направлением убывания
\end{theorem}
\begin{proof}
Из свойства дифференцируемости функции и условия данной теоремы следует, что \[f(x^{k + 1}) - f(x^k) = f(x^k + \alpha p^k) - f(x^k) = (\nabla f(x^k), \alpha p^k) + o(\alpha) = \]
\[ = \alpha \left((\nabla f(x^k), p^k) + \frac{o(\alpha)}{\alpha}\right) < 0 \]
, при всех достаточно малых \(\alpha > 0\), т.е. \(p^k\) задает направление убывания функции \(f(x)\) в точке \(x^k\)
\end{proof}
\begin{remark}
Геометрическая интерпретация \((\nabla f(x^k), p^k) < 0\) \implies \(p^k\) составляет тупой угол с \(\nabla f(x^k)\)
\end{remark}

\noindent\rule{\textwidth}{0.5pt}
\(f(x)\) дифференцируема в \(E_n\):
\[ x^{k + 1} = x^k + \alpha_k p^k \quad k = 0,1,\dots \addtag\label{11_8}\]
где \(p^k\) определяется с учетом информации о частных производных, а величина шага \(\alpha_k > 0\), такова, что:
\[ f(x^{k + 1}) < f(x^k) \quad k = 0,1,\dots \addtag\label{12_8}\]
Останов итерационного процесса: \(\Vert \nabla f(x^k) \Vert < \varepsilon\)
\section{Метод градиентного спуска}
\label{sec:org5e0dff6}
В \ref{11_8}: \(p^k = - \nabla f(x^k)\) --- предположение. Если \(\nabla f(x^k) \neq 0\), то \((\nabla f(x^k), p^k) < 0\), следовательно \(p^k\) --- направление убывания функции \(f(x)\), в малой окрестности точки \(x^k\) направление \(p^k\) обеспечивает \uline{наискорейшее} убывание этой функции. Таким образом можно найти такое \(\alpha_k > 0\), что выполнится \ref{12_8}
\begin{rualgo}[H]
\caption{метод Градиентного спуска}
\begin{algorithmic}[1]
\REQUIRE \(\varepsilon > 0\), \(\alpha > 0\), \(x \in E_k\), \(f(x)\)
\LOOP
  \STATE Вычисляем \(\nabla f(x)\)
  \IF{Выполнено условие достижения точности \(\Vert \nabla f(x) \Vert < \varepsilon\)}
    \RETURN \(x^* := x\), \(f^* := f(x^*)\)
  \ENDIF
  \LOOP
    \STATE Найти \(y := x - \alpha \nabla f(x)\)
    \STATE Вычислить \(f(y)\)
    \IF{\(f(y) < f(x)\)}
      \STATE \(x := y\)
      \STATE \(f(x) := f(y)\)
      \STATE Выйти из цикла
    \ELSE
      \STATE \(\alpha := \frac{\alpha}{2}\)
    \ENDIF
  \ENDLOOP
\ENDLOOP
\end{algorithmic}
\end{rualgo}
\begin{remark}
В окрестности стационарной точки функции \(f(x)\) величина \(\Vert \nabla f(x) \Vert\) становится малой, это приводит к замедлению сходимости полседовательности \(\{x^k\}\). Поэтому в \ref{11_8} иногда полагают
\[ p^k = \frac{-\nabla f(x^k)}{\Vert \nabla f(x^k) \Vert} \]
\end{remark}
\begin{theorem}
Пусть симметричная матрица \(A\) квадратичной функции \(f(x)\) положительно определена, а \(l\) и \(L\) --- наименьшее и наибольшее собстенное значение \(A\). Тогда при любых \(\alpha \in (0, \frac{2}{L})\) и \(x^0 \in E_n\)
\[ x^{k + 1} = x^k - \alpha \nabla f(x^k) \]
сходится к единственной точке глобального минимума \(x^*\) функции \(f(x)\) линейно (со скоростью геометрической прогрессии)
\[ \rho(x^k, x^*) \le q^k \rho(x^0, x^*) \]
, где \(q = \max \{| 1 - \alpha l|, |1 - \alpha L|\}\)
\end{theorem}
\begin{proof}
Т.к. \(A\) положительно определена, то \(f(x)\) --- сильно выпукла. Следовательно точка \(x^*\) --- существует и единственна. \(\nabla f(x^*) = 0\) в точке \(x^*\), тогда
\[ \nabla f(x^k) = A x^k + b = A x^k + b - \underbrace{A x^* - b}_{\nabla f(x^*)} = A(x^k - x^*) \]
Оценим норму разности
\[ \Vert x^k - x^* \Vert = \Vert x^{k - 1} - \alpha \nabla f(x^{k - 1}) - x^* \Vert = \Vert x^{k - 1} - x^* - \alpha A(x^{k - 1} - x^*) \Vert = \]
\[ = \Vert (E - \alpha A) (x^{k - 1} - x^*)  \Vert \]
\[ \Vert x^k - x^* \Vert \le \Vert E - \alpha A \Vert \cdot \Vert x^{k - 1} - x^* \Vert \le q \Vert x^{k - 1} - x^* \Vert \le q^k \Vert x^0 - x^* \Vert \]
--- из определения линейной сходимости, где \(q\) --- оценка нормы матрицы через величину ее собственных значений
\[ \Vert E - \alpha A \Vert \le q = \max \{|1 - \alpha l|, |1 - \alpha L|\} \]
Если \(\alpha \in (0; \frac{2}{L})\), то \(q < 1\) \\
q: \(q^* = \frac{L - l}{L + l}\), при \(\alpha = \alpha^* = \frac{2}{L + l}\). Т.к. \(l < L\), то \(1 - \alpha l = - (1 - \alpha L)\). От соотношения \(L\) и \(l\) существенно зависит число итераций градиентного метода при минимизации выпуклой квадратичной функции
\end{proof}
\begin{examp}
\(L = l > 0\), тогда точка минимума находится за один шаг
\[ f(x) = x_1^2 + x_2^2 \to \min \]
\[ x^0 = (1, 1)^T \quad \alpha = \alpha^* = \frac{2}{l + L}\]
\end{examp}
\begin{solution}
\[ A = \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix} \implies l = L = 2 \]
\[ \alpha^* = \frac{2}{2 + 2} = \frac{1}{2} \]
\[ x^1 = x^0 - \frac{1}{2}\ nabla f(x^0) = (0, 0)^T \]
\[ x^1 = x^* \]
\end{solution}
\begin{remark}
При \(l = L\) --- линии уровня \(f(x)\) --- концентрические окружности
\end{remark}
\begin{remark}
\(L >> l > 0\) --- линии уровня \(f(x)\) --- эллипсы
\end{remark}
\begin{examp}
\[ f(x) = x_1^2 + 100x^2_2 \to \min \]
\[ x^0 = (1, 1)^T \]
\[ \alpha = \alpha^* \]
\end{examp}
\begin{solution}
\[ A = \begin{pmatrix} 2 & 0 \\ 0 & 200 \end{pmatrix} \implies l = 2,\ L = 200\]
Линии уровня --- эллипсы сильно вытянутые вдоль оси \(Ox_1\)
\[ \alpha = \alpha^* = \frac{2}{202} = \frac{1}{101} \]
\[ -\nabla f(x^0) = (-2, -200)^T \]
--- сильно отличается от \(x^* - x^0\)
\[ x^* - x^0 = (-1, -1)^T \]
--- направление точки глобального минимума
\[ x^{k + 1} = x^k - \alpha \nabla f(x^k) \]
\[ \nabla f(x^k) = (2x_1, 200x_2)^T \]
\[ \begin{cases}
x_1^{k + 1} = \frac{99}{101} x_1^k \\
x_2^{k + 1} = - \frac{99}{101} x_2^k
\end{cases}\]
--- закон изменения координат точек, минимизирующей последовательности. \(\{x^k\}\) --- сходится медленно
\end{solution}
\begin{definition}
\textbf{Число обусловленности} для симметричной положительно определенной матрицы \(\mu = \frac{L}{l}\). Оно характеризует вытянутость линий уровня \(f(x) = C\)
\begin{itemize}
\item Если \(\mu\) велико, то линии уровня сильно вытянуты и говорят что функция имеет \textbf{овражный} характер (резко меняется по одним направлением и слабо по другим) \(\implies\) \uline{Полохо обусловленная задача}
\item Если \(\mu \sim 1\), то линии уровня близки к окружностям и задача является \uline{хорошо обусловленной}
\end{itemize}
\end{definition}
\section{Метод наискорейшего спуска}
\label{sec:orgec93147}
После вычисления в начальной точке градиента функции делают в направлении антиградиента не маленький шаг, а передвигаются до тех пор, пока функция убывает. Достигнув точки минимума на выбранном направлении снова вычисляют градиент функции и повторяют описанную процедуру
\[ p^k = -\nabla f(x^k) \]
\(\alpha_k\) --- находится из решения задачи одномерной оптимизации
\[ \Phi_k(\alpha) \to \min \]
\[ \Phi_k(\alpha) = f(x^k - \alpha \nabla f(x^k)) \quad \alpha > 0 \addtag\label{13_8} \]
\begin{rualgo}[H]
\caption{метод наискорейшего спуска}
\begin{algorithmic}[1]
\REQUIRE \(\varepsilon > 0\), \(x \in E_k\), \(f(x)\)
\LOOP
  \STATE Вычислить \(\nabla f(x)\)
  \IF{\(\Vert \nabla f(x) \Vert < \varepsilon\)}
    \RETURN \(x^* := x\), \(f^* := f(x)\)
  \ENDIF
  \STATE Решить задачу одномерной оптимизации \ref{13_8} для \(x^k := x\), т.е. найти \(\alpha^*\)
  \STATE \(x := x - \alpha^* \nabla f(x)\)
\ENDLOOP
\end{algorithmic}
\end{rualgo}
\begin{definition}
Ненулевые векторы \(p^1,\dots, p^k\) называются сопряженными относительно матрицы \(A\) размера \(n \times n\) или \(A\)-ортогональными, если
\[ (Ap^i, p^j) = 0 \quad i\neq j \quad i, j = 1,\dots,k\]
\end{definition}
\begin{remark}
Система из \(n\) векторов \(p^1,\dots,p^n\) сопряженных относительно положительно определенной матрицы \(A\) линейно независима
\end{remark}
\begin{remark}
\(n\) ненулевых \(A\)-орттгональных векторов образуют базис в \(E_n\).Рассмотрим минимизацию квадратичной функции в \(E_n\)
\[ f(x) = \frac{1}{2} (Ax, x) + (b, x) + c \]
\(A\) --- положительно определенная. Итерационный процесс
\[ x^k = x^{k - 1} + \alpha_k p^k \quad k = 1,2,\dots \addtag\label{14_8} \]
, где \(p^k\) --- \(A\)-ортогональные
\end{remark}
\begin{remark}
Если в итерационном процессе \ref{14_8} на каждом жаге используется исчерпывающий спуск, то
\[ \alpha_k = -\frac{(\nabla f(x^0), p^k)}{(Ap^k, p)} \quad k = 1,2,\dots \addtag\label{15_8} \]
\end{remark}
\begin{proof}
\[ x^k = x^{k - 1} + \alpha_k p^k = x^0 + \sum_{i = 1}^{k} \alpha_i p^i \addtag\label{16_8} \]
\[ \nabla f(x) = Ax + b \]
\[ \nabla f(x^k) = \nabla f(x^0) + \sum_{i = 0}^k \alpha_i A p^i \]
домножим на \(p^k\) и учитываем \((\nabla f(x^k), p^k) = 0\), \(A\)-ортогональность \(p^k\)
\[ (\nabla f(x^0), p^k) + \alpha_k (A p^k, p^k) = 0 \]
, т.к. \(A\) --- положительно определена, то \((A p^k, p^k) > 0\), и для \(\alpha_k\):
\[ \alpha_k = -\frac{(\nabla f(x^0), p^k)}{(A p^k, p^k)} \]
\end{proof}
\end{document}
