#+setupfile: setup.org
#+TITLE: Лекция 2
#+date: 8 сентября


* Декодирование
#+begin_definition org
Критерий минильного расстояния \(X = Y\). Декодер ищет кодово слово
\[ c = \argmin_{c \in \Co} d(c, y) \]
#+end_definition

#+begin_definition org
Алгоритм называется алгоритмом полного декодирования по критерию \(K\), если он способен найти решение соответствующуй оптимизационной задачи для любого возможного принятого сигнала
#+end_definition

* Метрики
#+begin_definition org
Функция \(d(x, y)\) называется метрикой, если:
- \(d(x, y) \ge 0, d(x, y) = 0 \Leftrightarrow x = y\)
- \(d(x, y) = d(y, x)\)
- Неравенстно треугольника \(d(x, y) + d(y, z) \ge d(x, z)\)
#+end_definition

#+begin_definition org
Метрическое пространство -- множество \(X\) с определенной на нем метрикой
#+end_definition

#+begin_examp org
Расстояние Хемминга \(d_H (x, y) = |\{i|x_i \neq y_i\}|\). Двоичный симметричный канал \((p < 0.5, X = Y = \{0, 1\}\):
\[ \hat{c} = \argmax_{x \in \Co} \prod_{i = 1}^n P\{y_i|c_i\} = \dots = \argmin_{c \in \Co} \sum_{i = 1}^na |y_i - c_i| \]
#+end_examp

#+begin_examp org
Расстояние Евклида \(d_E(x, y) = \sqrt{\sum_{i = 1}^n (x_i - y_i)^2}\). Аддитивный Гауссовский канал с амплитудно-импульсной модуляцией \((Y = \R^n)\).
#+end_examp

#+begin_examp org
Расстояние Ли \((A = GF(q)^n): d_L(x, y) = \sum_{i = 1} \min(|x_i - y_i|, q - |x_i - y_i|)\). Аддитивный Гауссовский канал с \(q\)-ичной фазовой модуляцией
#+end_examp

#+begin_examp org
Ранговое расстояние \((A = GF(q)^{n \times m}): d_R (x, y) = \rank(x - y)\). Сетевые коды
#+end_examp



* Кодирование
Операция канального кодирования вносит в информационную
последовательность избыточность, необходимую для последующего
исправления возможных ошибок

Блоковые коды преобразуют блок из \(k\) символов в блок из \(n\) символов. Преобразование отдельных блоков выполняется независимо

Сверточные коды преобразуют блок из \(k\) символов в блок из \(n\) символов. Преобразование зависит от предыдущих блоков.

** Блоковые коды
\(n\) -- длина коды \(\Co\). Для исправления ошибок требуется, чтобы не
все \(|X|^n\) последовательностей были кодовыми словами. Мощность кода
(число различных кодовых слов) \(M = |C|\).

#+begin_rem org
Скорость кода: \(R = \frac{\log_{|X|}M}{n} \).
#+end_rem

#+begin_definition org
Минимальным расстоянием кода называется минимальное расстояние Хемминга между его различными кодовыми словами
#+end_definition
#+begin_examp org
Пример \(C = \{000, 111\}, d_{m \times n}(C) = 3\)
#+end_examp

#+begin_rem org
Хеммингов шар радиуса \(d_\min - 1\), описанный вокруг кодового слова \(c \in C\), не содержит никаких других кодовых слов
#+end_rem

#+begin_statement org
Код с минимальныи расстоянием Хемминга \(d\) способен исправить \(\left\llbracket \frac{d - 1}{2} \right\rrbracket\)
#+end_statement

** Линейный код
#+begin_definition org
*Линейным \((n, k)\) (длины \(n\) размерностью \(k\)) кодом* \(C\) называется \(k\)-мерное линейное подпространство \(n\)-мерного линейного пространства над полем \(GF(q)\).
#+end_definition

#+begin_rem org
Число кодовых слов равно \(q^k\)
#+end_rem

#+begin_definition org
Порождающая \(k \times n\) матрица полного ранга \(G: C = \{y = xG|x \in GF(q)^k\}\)
#+end_definition
#+begin_definition org
Проверочная матрица \(r \times n\), \(H: C = \{y \in GF(q)^n|yH^T = 0\}\), \(r \ge n - k = \rank(H)\)
\[ GH^T = 0 \]
#+end_definition

#+begin_rem org
С помощью линейных операций над стоками и перестановок столбцов порождающая матрица может быть приведена к виду \(G = (I | A)\). \\
*NB* Вообще говоря перестановкой столбцов получаеи порождающую матрицу другого коды, поэтому перестановка столбцов в порождающей матрице должна быть согласована с перестановкой в проверочной
#+end_rem

#+begin_rem org
Систематическое кодирование \(xG = (x | xA)\) -- информационный вектор является подвектором кодого слова. Применение систематического кодирования упрощает декодирование
\[ H = (A^T|-I) \]
#+end_rem

#+begin_statement org
Минимальное расстояние линейного блокового кода \(\Co\) равно \(d = \min_{\substack{c' \neq c'' \\ c', c'' \in \Co}} d(c', c'') = \min_{c \in \Co \setminus \{0\}} wt(c)\), где \(wt(c)\) -- вес вектора (количество единиц)
#+end_statement
#+begin_proof org
Расстояние между двумя векторами -- число позиций в которых они отличаются
#+begin_export latex
\begin{center}
\begin{align*}
  d(c', c'') = \sum_{i = 0}^n d(x, y) = \sum_{i = 0}^n d(0, x - y) = d(0, c' - c'')
\end{align*}
\end{center}
#+end_export
Так как код образует линейное подпространство, значит он группа по сложение, значит \(c' - c''\) -- кодовое слово. \(wt(c)\) -- вес Хемминга
#+end_proof

#+begin_statement org
Если \(H\) -- проверочная матица кода длины \(n\), то код имеет размерность \(n - r\) \(\Leftrightarrow\) существуют \(r\) линейно независимых столбцов матрицы \(H\), а любые \(r + 1\) столбцов линейно независимы
#+end_statement

#+begin_statement org
Если \(H\) -- проверочная матрица кода длины \(n\), то код имеет минимальное расстояние \(d\) \(\Leftrightarrow\) любые \(1, 2, \dots, d - 1\) столбцов \(H\) линейно независимы, но существуют \(d\) линейно зависимых столбцов матрицы \(H\)
#+end_statement

#+begin_rem org
Принадлежность коду \(yH^T = 0\) эквивалентна ЛЗ столбцов
#+end_rem

#+begin_statement org
Граница Синглтона (верхняя): для любого \((n, k, d)\) линейного кода \(n - k \ge d - 1\)
#+end_statement
#+begin_corollary org
Ранг матрицы \(H\) (максимальное число ЛНЗ столбцов) не может превосходить \(n - k\)
#+end_corollary

#+begin_definition org
Граница Синглтона для произовльных кодов \(A_q(n, d) \le q^{n - d + 1}\)
#+end_definition

#+begin_definition org
Коды с \(n - k = d - 1\) называются *разделимыми* кодами с максимальным достижимым расстоянием
#+end_definition

    
** Простейшие коды
#+begin_examp org
Пусть \(G\) -- обратимая \(n \times n\) матрица. Она порождает код \((n, n, 1)\).
#+end_examp

#+begin_examp org
\((n, 1, n)\) код с \(n\)-кратным повторением: \(G' = (11\dots 1)\),
#+begin_export latex
\begin{center}
\begin{align*}
H' = \begin{pmatrix}
  1 & 0 & 0 & \dots & 0 & 1 \\
  0 & 1 & 0 & \dots & 0 & 1 \\
  0 & 0 & 1 & \dots & 0 & 1 \\
  \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
  0 & 0 & 0 & \dots & 1 & 1
\end{pmatrix}
\end{align*}
\end{center}
#+end_export
#+end_examp

#+begin_examp org
\((n, n - 1, 2)\) код с проверкой на четность:
#+begin_export latex
\begin{center}
\begin{align*}
G'' = \begin{pmatrix}
  1 & 0 & 0 & \dots & 0 & 1 \\
  0 & 1 & 0 & \dots & 0 & 1 \\
  0 & 0 & 1 & \dots & 0 & 1 \\
  \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
  0 & 0 & 0 & \dots & 1 & 1
\end{pmatrix}, 
H'' = \begin{pmatrix} 1 & 1 & \dots & 1 \end{pmatrix}
\end{align*}
\end{center}
#+end_export

#+end_examp

* Декодирование

** Код Хемминга
Выберем в качестве столбцов матрицы \(H\) все ненулевые двоичные векторы длины \(r\):
- Длина кода \(n = 2^r - 1\)
- Размерность \(k = n - r = 2^r - r - 1\)
- Минимальное расстояние \(d = 3\)

#+begin_examp org
Если столбцы выписаны в соответсвии с двоичным кодом:
#+begin_export latex
\begin{center}
\begin{align*}
H = \begin{pmatrix}
  1 & 0 & 1 & 0 & 1 & 0 & 1 \\
  0 & 1 & 1 & 0 & 0 & 1 & 1 \\
  0 & 0 & 0 & 1 & 1 & 1 & 1
\end{pmatrix}
\end{align*}
\end{center}
#+end_export
#+end_examp

** Жесткое и мягкое декодирование
В классичесической архитектуре предполагается что модулятор преобразует закодированные данные в сигнал, демодулятор оценивает символы кодовых слов, а декодер потом пытается исправить ошибки. Такой подход плох тем что теряется информация о надежности отдельных принятых символов.
Сейчас как правило используют мягкое декодирование: демодулятор каким-то образов формирует информацию о надежности отдельных принятых символов, декодер при исправлении пытается учесть эту информацию.

** Жесткое декодирование линейных кодов
Рассмотрим двоичный симметричный канал с переходной вероятностью \(p <
0.5\). Предположим что передатчик использует линейный блоковый код с
порождающей матрицей \(G\). Тогда принятый вектор \(y = xG + e\), где
\(e\) -- вектор ошибки, который содержит \(1\) на тех позициях где
произошла ошибка.

#+begin_definition org
*Синдром* принятого вектора \(S = yH^T = xGH^T + eH^T = eH^T\) зависит только от вектора ошибки
#+end_definition

#+begin_definition org
Пусть есть подгруппа некоторой группы \(G\), \(G' \subset G\). Возьмем элемент \(a \in G\), то *смежным классом* подгруппы \(G'\), называется \(a G' = \{a \cdot x | x \in G'\} \subseteq G\)
#+end_definition

#+begin_definition org
*Лидер смежного класса* -- минимальный по весу вектор.
#+end_definition


Рассмотрим все возможные вектора \(e\) и выпишем соответсвующие синдромы. Отсортируем по весу все возможные вектора \(e\), соответствующие каждому возможному значению синдрома (/стандартная расстановка/). В качестве решения задачи декодирования выбираем самый легкий вектор \(e\), соответствующий вычисленному синдрому:

** Код хемминга (продолжение)
Если произошла только одна ошибка, то \(S = eH^T\) будет равно какому-то столбцу матрицы \(H\). Получается синдром -- двоичное представление числа, которое является номеру позиции в которой произошла ошибка.

** Стирание
Некоторые символы могут просто теряться. Стирания могут происходить одновременно с ошибками. Утверждается что \((n, k, d)\) код может исправить любую комбинацию из \(t\) ошибок и \(v\) стираний, если \(d \ge 2t + v + 1\). Стирание эквивалентно выкалыванию кода на \(v\) позиций \(\implies\) минимальное расстояние уменьшается не более чем на \(v\).
#+begin_rem org
Декодирование ошибок и стираний для кодов над \(GF(2)\):
- Положить все стертые позиции равными \(0\), исправить ошибки в полученном векторе
- Положить все стертые позиции равными \(1\), исправить ошибки в полученном векторе
- Выбрать результат декодирования, ближайший к принятому вектору
#+end_rem


* Качество (performace) декодирования
#+begin_definition org
*Весовой спектр кода* \(A_i = | \{c \in C | wt(c) = i\} |\).
#+end_definition

Рассмотрим двоичный симметричный канал с переходной вероятностью \(p\). Вероятность не обнаружения ошибки:
\[ P_{\text{undetect}} = P \{ S = 0 \} = \sum_{i = d}^n A_i p^i(1 - p)^{n - i} \le \sum_{i=d}^n C^i_n p^i (1 - p)^{n - i} \]

Вероятность правильного декодирования. Вероятность того, что вектор ошибки является лидером смежного класса:
\[ P_{\text{correct}} = \sum_{i = 0}^l L_i p^i(1 - p)^{n - i} \],
где \(L_i\) -- число лидеров смежных классов веса \(i\), \(l\) -- максимальный вес лидера смежного класса

* Декодирование по информационным совокупностям
#+begin_definition org
*Информационной совокупностью* называется множество из \(k\) позиций в кодовом слове, занчения которых однозначно определяют значения на остальных позициях кодового слова 
#+end_definition

#+begin_definition org
Если \(\gamma = \{j_1, \dots, j_k\}\) -- ИС, то все прочие позиции \(\{1, \dots, n\} \setminus \gamma\) образуют *проверочную совокупносить*
#+end_definition

#+begin_statement org
Если \(\gamma = \{j_i, \dots, j_k\}\) образует ИС, то матрица, составненная из столбцов \(j_1, \dots, \j_k\) порождающей матрицы, обратима
#+end_statement

#+begin_proof org
\(G = (A | B)\) -- порождающая матрица. Если матрица \(A\) -- необратима, у нее есть линейно зависимые столбцы или строки, значит \(\exists x \neq 0: xA = 0\). Есть кодовое \(c = (c' | c'')\):
\[ c + xG = (c' | c'') + (xA | xB) = (c' + xA | c'' + xB) = (c' | c'' + xB) \]
\(xB \neq 0\) т.к. вся линейно зависимость осталась в матрице \(A\). Получилось новое кодовое слово, которые совпадает с начальным на позициях \(c'\). Получается что смотря на эти позиции нельзя однозначно указать значения на остальных позициях. Значит это не информационная совокупность. Противоречие, значит \(A\) -- обратимая
#+end_proof

#+begin_definition org
\(M(\gamma) = A^{-1}\)
#+end_definition

#+begin_statement org
\(G(\gamma) = M(\gamma)G\) -- породжающая матрица, содержащая единичную подматрицу на столбцах \(\gamma\), где \(M(\gamma)\) -- подходящая обратимая матрица
#+end_statement

#+begin_rem org
\(G = (A | B), G(\gamma) = (\overbrace{I}^\gamma | M(\gamma) B)\)
#+end_rem


#+begin_definition org
ИС *свободна от ошибок*, если соответствующие позиции вектора \(e\) равны \(0\): \(e(\gamma) = 0\)
#+end_definition

** Декодирование
Декодирование \(y = xG + e\) по информационным совокупностям:
- (первоначальный кандидат) \(c = 0\)
- Выбрать ИС \(\gamma\). Вычислить \(c ' = y(\gamma) G(\gamma)\)
- Если \(d(c', y) < d(c, y), c = c'\)
- Перейти к следующей ИС. Если все ИС проверены, возвратить \(c\).
- Не всякие \(k\) позиций образуют информационную совокупность
