#+setupfile: setup.org
#+TITLE: Лекция 1
#+date: 2 сентября


* Введение
#+ATTR_LATEX: :width 0.3\textwidth
[[file:1.1.png]]

** Модулятор
Передаваемый сигнал равен
\[ x(t) = \sum_i S_{x_i} (t - iT) \],
где \(x_i\) -- передаваемые символы, \(T\) -- продолжительность символьного интервала

#+begin_examp org
\(M\)-ичная амплитудно-импульсная модуляция
\[ S_i(t) = \alpha(2i + 1 - M)g(t)\sin(2\pi f t) \],
где \(g(t)\) -- сигнальный импульс (например, единичный импульс продолжительностью \(T\)), \(f\) -- несущая частота,
\(\alpha\) -- коэффицент, определяющий энергию передаваемого сигнала
#+end_examp
#+begin_examp org
Модель канала в непрервном времени \(y(t) = x(t) + \eta(t)\)
#+end_examp
#+begin_examp org
Модель канала в дискретном времени \(y_i = \alpga(2x_i + 1 - M) + \eta_i\)
#+end_examp
#+begin_definition org
\(\eta_i \sim \mathcal{N}(0, \sigma^2)\) -- канал с *аддитивным белым гауссовским шумом*
#+end_definition

** Приемник
Приемник наблюдает на выходе канала вектор \(y = \begin{pmatrix} y_0 & \dots & y_{n - 1} \end{pmatrix} \). \\
Канал характеризуется условным распределением \(p_{Y|X}(y|x)) \), где \(X, Y\) -- случайные величины, соответствующие векторам переданных и принятых символов.
Если выход канала -- непрерывная случайная величина, \(p_{Y|X}(y|x)} \) -- условная плотность вероятности

#+begin_definition org
Вероятность ошибки
\[ P_e = \int_{\R^N} P_e(y)p_Y(y) dy = \sum_x \int_{R_x} p_e(y) p_Y(y) dy = \]
\[ = \sum_x\int_{R_x} (1 - p_{X|Y}(x|y)) p_Y(y) dy = 1 - \sum_x\int_{R_x}p_{X|Y}(x|y) p_Y(y) dy \]
#+end_definition

Хотим минимизировать \(P_e\):

#+begin_definition org
Критерий максимума апостериорной вероятности (критерий идеального наблюдателя)
\[ R_x = \{y|p_{X|Y}(x|y) > p_{X|Y}(x'|y), x' \neq x \} = \{ y | P_X(x) p_{Y|X}(y|x) > P_X (x') p_{Y|X}(y|x'), x' \neq x \} \]
#+end_definition

#+begin_definition org
Критерий максимума правдоподобия
\[ R_x = \{y | p_{Y|X}(y|x) > p_{Y|X}(y | x'), x' \neq x\} \]
#+end_definition
* Понятие кода
#+begin_definition
*Код* -- множество допустимых последовательностей символов алфавита \(X\), как конечных так и бесконечных
#+end_definition
#+begin_remark
На практике ограничиваются послеловательностями длины \(n\)
#+end_remark
#+begin_remark
Не всякая последовательность символов из \(X\) является кодовой
#+end_remark

#+begin_definition
Кодер -- устройство, реализующее отображение информационных последовательностей символов алфавита \(B\)  в кодовые
#+end_definition
#+begin_remark
Различным информационным последовательностям сопоставляются разсличные кодовые последовательности
#+end_remark
#+begin_definition
*Скорость кода* -- отношение длин информационной и кодовой последовательностей
#+end_definition

#+begin_definition
*Декодер* -- устройство, восстанавливающее по принятой последовательности символов /наиболее вероятную/ соответствующую ей кодовую (или информационную) последовательность
#+end_definition
#+begin_remark
Под наиболее вероятным подразумевается критерии иделального наблюдателя и максимального правдоподобия
#+end_remark

** Теорема кодирование
Пусть для передачи используеся код \(\Co \subset X^n\) длины \(n\), состоящий из \(M\) кодовых слов, выбираемых с одинаковой вероятностью
#+ATTR_LATEX: :options [Обратная]
#+begin_theorem
Для дискретного постоянного канала с пропускной способностью \(C\) для любого \(\delta > 0\) существует \(\varepsilon > 0\) такое, что для любого кода со скоростью
\(R > C + \delta\) средняя вероятность ошибки \(\bar{P}_\varepsilon > \varepsilon\)
#+end_theorem
#+begin_remark
Постоянный канал -- статистические свойства со временем не меняются \\
Дискретный канал -- вход и выход дискретные
#+end_remark
#+begin_remark
Здесь говориться о том канал характеризуется величиной \(C\). Если попробуем передать данные с большей пропускной способностью, то вероятность ошибки будет ограничена снизу.
#+end_remark
#+ATTR_LATEX: :options [Прямая]
#+begin_theorem
Для дискретного постоянного канала с пропускной способностью \(C\) для любых \(\varepsilon, \delta > 0\) существует достаточно большое число \(n_0 > 0\), такое что
для всех натуральных \(n \ge n_0\) существует код длиной \(n\) со скоростью \(R \ge C - \delta\), средняя вероятность ошибки которого \(P_\varepsilon \le \varepsilon\)
#+end_theorem



** Пропускные способности каналов
#+begin_definition
Двоично симметричный канал: \(X, Y \in \{0, 1\}, p_{Y|X}(y|x) = \begin{cases} p, & y \neq x \\ 1 - p, & y = x \end{cases}\)
\[ C_{\text{BSC}} = 1 + p\log_2p + (1 - p)\log_2(1 - p) \]
#+end_definition

#+begin_definition org
Идеальный часточно ограниченный гауссовский канал \(y(t) = x(t) + \eta(t)\), \(\eta(t)\) -- гауссовский случайный процесс, спектральная плотность мощности которого
равна \(S(f) = \begin{cases} \frac{N_0}{2}, & -W < f < W \\ 0 & \text{иначе} \end{cases} \)
\[ C_{\text{AWGN}} = W \log_2 \left( 1 + \frac{E_s}{WN_0} \right) \]
#+end_definition


** Мягкое и жесткое декодирование
Канал с аддитивным белым гауссовским шумом: \(y_i = (2x_i - 1) + \eta_i, x_i \in \{0, 1\}\)
#+begin_definition
Мягкое декодирование: декодер непосредственно использует \(y_i\)
#+end_definition
#+begin_definition
Жесткое декодирование: декодер использует оценки \(\hat{x}_i\)
#+end_definition


** Спектральная эффективность
#+begin_definition org
Спектральная эффективность кодирования \(\beta = \frac{R}{W} \ \left[ \frac{\text{бит}}{\text{сГц}} \right]\)
#+end_definition

