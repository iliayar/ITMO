#+TITLE: Lab 6

#+begin_src jupyter-python
import sys
sys.executable 
#+end_src

#+RESULTS:
: # Out[1]:
: : '/nix/store/my9c3h8021nf6zqi8qqqm4asnh2319js-python3-3.9.6-env/bin/python3.9'

* Imports
#+begin_src jupyter-python
import torch
import torchvision
import torchvision.transforms as transforms

import random

import numpy as np
import matplotlib.pyplot as plt

import torch.nn as nn
import torch.nn.functional as F

import torch.optim as optim

from mpl_toolkits.axes_grid1 import ImageGrid

from tqdm import tqdm

import seaborn as sns
#+end_src

#+RESULTS:
: # Out[2]:

* Settings
#+begin_src jupyter-python
RANDOM_SEED = 42
BATCH_SIZE = 10 
#+end_src

#+RESULTS:
: # Out[3]:

#+begin_src jupyter-python
torch.manual_seed(RANDOM_SEED)
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
#+end_src

#+RESULTS:
: # Out[5]:


* Load datasets

#+begin_src jupyter-python
transform = transforms.Compose([
    transforms.ToTensor(),
])

mnist_train = torchvision.datasets.MNIST('data/mnist', download=True, transform=transform, train=True)
mnist_test = torchvision.datasets.MNIST('data/mnist', download=True, transform=transform, train=False)
fashion_mnist_train = torchvision.datasets.FashionMNIST('data/mnist', download=True, transform=transform, train=True)
fashion_mnist_test = torchvision.datasets.FashionMNIST('data/mnist', download=True, transform=transform, train=False)

mnist_train_loader = torch.utils.data.DataLoader(mnist_train,
                                                batch_size=BATCH_SIZE,
                                                shuffle=True)
mnist_test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=len(mnist_test))

fashion_mnist_train_loader = torch.utils.data.DataLoader(fashion_mnist_train,
                                                batch_size=BATCH_SIZE,
                                                shuffle=True,)
fashion_mnist_test_loader = torch.utils.data.DataLoader(fashion_mnist_test, batch_size=len(fashion_mnist_test))
#+end_src

#+RESULTS:
: # Out[6]:

#+begin_src jupyter-python :results raw drawer
mnist_train
#+end_src

#+RESULTS:
:results:
# Out[7]:
#+BEGIN_EXAMPLE
  Dataset MNIST
  Number of datapoints: 60000
  Root location: data/mnist
  Split: Train
  StandardTransform
  Transform: Compose(
  ToTensor()
  )
#+END_EXAMPLE
:end:


#+begin_src jupyter-python :results raw drawer
images, labels = next(iter(mnist_train_loader))
print(np.shape(images))
plt.imshow(np.transpose(images[0], (1, 2, 0)))
plt.show()
#+end_src

#+RESULTS:
:results:
# Out[8]:
[[file:./obipy-resources/A3Uwet.png]]
:end:

#+begin_src jupyter-python :results raw drawer
images, labels = next(iter(fashion_mnist_train_loader))
print(np.shape(images))
plt.imshow(np.transpose(images[0], (1, 2, 0)))
plt.show()
#+end_src

#+RESULTS:
:results:
# Out[77]:
[[file:./obipy-resources/kQZsYS.png]]
:end:

* Train

#+begin_src jupyter-python
criterion = nn.CrossEntropyLoss()
#+end_src

#+RESULTS:
: # Out[9]:


#+begin_src jupyter-python
def make_optimizer(net):
    return optim.Adam(net.parameters())
#+end_src

#+RESULTS:
: # Out[17]:

#+begin_src jupyter-python
def train(net, data_loader, epoch=5, loss_dens=100):
    loss_log = []
    net = net.to(device)
    for epoch in range(epoch):
    
        running_loss = 0.0
        for i, data in enumerate(tqdm(data_loader), 0):
    
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)
    
            optimizer.zero_grad()
    
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
    
            running_loss += loss.item()
    
            if i % loss_dens == loss_dens - 1:
                loss_log.append(running_loss / loss_dens)
                running_loss = 0.0
    net = net.to('cpu')
    return loss_log
#+end_src

#+begin_src jupyter-python
def show_loss_log(loss_log):
    plt.figure(figsize=(8, 6))
    plt.plot(loss_log)
    plt.show()
#+end_src


#+begin_src jupyter-python
def accuracy(net, data_loader):
    data, labels = next(iter(data_loader))
    preds = net(data)
    print(preds.argmax(dim=1))
    labels_pred = preds.argmax(dim=1).detach().numpy()
    T = 0
    for label_true, label_pred in zip(labels, labels_pred):
        T += label_pred == label_true
    return T / len(mnist_test)
#+end_src

#+RESULTS:
: # Out[25]:

#+begin_src jupyter-python
def show_confusion_matrix(net, data_loader):
    data, labels = next(iter(data_loader))
    preds = net(data)
    stacked = torch.stack((labels, preds.argmax(dim=1)), dim=1)
    cmt = torch.zeros(10, 10, dtype=torch.int64)
    for p in stacked:
        tl, pl = p.tolist()
        cmt[tl, pl] += 1
    plt.figure(figsize=(16, 9))
    sns.heatmap(cmt, annot=True, cmap='Blues', fmt='d')
    plt.show()
#+end_src

#+RESULTS:
: # Out[33]:

#+begin_src jupyter-python
def show_similar(net, data_loader):
    data, labels = next(iter(data_loader))
    preds = net(data)
    msi = [[None for i in range(10)] for i in range(10)]
    for d, p, l in zip(data.to('cpu'), preds, labels):
        for i in range(10):
            if msi[l][i] == None or msi[l][i][0] < p[i]:
                msi[l][i] = (p[i], d)
    
    fig = plt.figure(figsize=(10, 10))
    grid = ImageGrid(fig, 111, nrows_ncols=(10, 10))
    
    for i, ax in enumerate(grid):
        ax.imshow(np.transpose(msi[i // 10][i % 10][1], (1, 2, 0)))
    
    plt.show()
#+end_src

#+RESULTS:
: # Out[43]:

** Attempt 1 =0.9285=

#+begin_src jupyter-python
net = nn.Sequential(
    nn.Conv2d(1, 8, 5), # 24
    nn.MaxPool2d(2, 2), # 12
    nn.Conv2d(8, 1, 3), # 10
    nn.MaxPool2d(2, 2), # 5
    nn.Conv2d(1, 100, 5), # 1
    nn.Flatten(),
    nn.Linear(100, 10),
    nn.Softmax(1),
)
#+end_src

#+RESULTS:
: # Out[49]:

#+begin_src jupyter-python :async yes
optimizer = make_optimizer(net)
loss_log = train(net, mnist_train_loader) 
#+end_src

#+RESULTS:
: # Out[50]:

#+begin_src jupyter-python :results raw drawer
show_loss_log(loss_log) 
#+end_src

#+RESULTS:
:results:
# Out[51]:
[[file:./obipy-resources/loO758.png]]
:end:


#+begin_src jupyter-python :results raw drawer
accuracy(net, mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[52]:
: tensor(0.9285)
:end:

#+begin_src jupyter-python :results raw drawer
show_confusion_matrix(net, mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[53]:
[[file:./obipy-resources/i0K6AW.png]]
:end:


#+begin_src jupyter-python :results raw drawer
show_similar(net, mnist_test_loader) 
#+end_src

#+RESULTS:
:results:
# Out[54]:
[[file:./obipy-resources/Qoah49.png]]
:end:

#+begin_src jupyter-python
net1 = net 
#+end_src

#+RESULTS:
: # Out[55]:

** Attempt 2 =0.9810=

#+begin_src jupyter-python
net = nn.Sequential(
    nn.Conv2d(1, 8, 5), # 24
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 12
    nn.Conv2d(8, 16, 5), # 8
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 4
    nn.Conv2d(16, 32, 4), # 1
    nn.Flatten(),
    nn.Linear(32, 10),
    nn.Softmax(1),
)
#+end_src

#+RESULTS:
: # Out[60]:

#+begin_src jupyter-python :async yes
optimizer = make_optimizer(net)
loss_log = train(net, mnist_train_loader) 
#+end_src

#+RESULTS:
: # Out[61]:

#+begin_src jupyter-python :results raw drawer
show_loss_log(loss_log) 
#+end_src

#+RESULTS:
:results:
# Out[62]:
[[file:./obipy-resources/6aYErl.png]]
:end:


#+begin_src jupyter-python :results raw drawer
accuracy(net, mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[63]:
: tensor(0.9810)
:end:

#+begin_src jupyter-python :results raw drawer
show_confusion_matrix(net, mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[64]:
[[file:./obipy-resources/byoALC.png]]
:end:


#+begin_src jupyter-python :results raw drawer
show_similar(net, mnist_test_loader) 
#+end_src

#+RESULTS:
:results:
# Out[65]:
[[file:./obipy-resources/TrdOAI.png]]
:end:

#+begin_src jupyter-python
net2 = net 
#+end_src

#+RESULTS:
: # Out[66]:

** Attempt 3 =0.9461=

#+begin_src jupyter-python
net = nn.Sequential(
    nn.Conv2d(1, 10, 3, padding=1), # 28
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 14
    nn.Conv2d(10, 25, 3), # 12
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 6
    nn.Conv2d(25, 50, 3), # 4
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 2
    nn.Conv2d(50, 100, 2), # 1
    nn.Flatten(),
    nn.Linear(100, 50),
    nn.ReLU(),
    nn.Linear(50, 10),
    nn.Softmax(1),
)
#+end_src

#+RESULTS:
: # Out[67]:

#+begin_src jupyter-python :async yes
optimizer = make_optimizer(net)
loss_log = train(net, mnist_train_loader) 
#+end_src

#+RESULTS:
: # Out[68]:

#+begin_src jupyter-python :results raw drawer
show_loss_log(loss_log) 
#+end_src

#+RESULTS:
:results:
# Out[69]:
[[file:./obipy-resources/RnzO0h.png]]
:end:


#+begin_src jupyter-python :results raw drawer
accuracy(net, mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[70]:
: tensor(0.9461)
:end:

#+begin_src jupyter-python :results raw drawer
show_confusion_matrix(net, mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[71]:
[[file:./obipy-resources/t3txgD.png]]
:end:


#+begin_src jupyter-python :results raw drawer
show_similar(net, mnist_test_loader) 
#+end_src

#+RESULTS:
:results:
# Out[72]:
[[file:./obipy-resources/SwrcHY.png]]
:end:

#+begin_src jupyter-python
net3 = net 
#+end_src

#+RESULTS:
: # Out[73]:

** Final
#+begin_src jupyter-python
net = nn.Sequential(
    nn.Conv2d(1, 8, 5), # 24
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 12
    nn.Conv2d(8, 16, 5), # 8
    nn.ReLU(),
    nn.MaxPool2d(2, 2), # 4
    nn.Conv2d(16, 32, 4), # 1
    nn.Flatten(),
    nn.Linear(32, 10),
    nn.Softmax(1),
)
#+end_src

#+begin_src jupyter-python :async yes
optimizer = make_optimizer(net)
loss_log = train(net, fashion_mnist_train_loader) 
#+end_src

#+RESULTS:
: # Out[74]:

#+begin_src jupyter-python :results raw drawer
show_loss_log(loss_log) 
#+end_src

#+RESULTS:
:results:
# Out[75]:
[[file:./obipy-resources/2KNHwv.png]]
:end:

#+begin_src jupyter-python :results raw drawer
accuracy(net, fashion_mnist_test_loader)
#+end_src

#+RESULTS:
:results:
# Out[78]:
: tensor(0.6055)
:end:
